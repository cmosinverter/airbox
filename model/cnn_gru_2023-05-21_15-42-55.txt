Train loss: [0.08366831311586828, 0.03201605775794309, 0.029136345010749305, 0.02656488335468516, 0.02426773910852835, 0.022253867189117038, 0.02053906139284207, 0.01913800524203298, 0.018048231731448684, 0.01723639902838199, 0.01664193018935807, 0.01619886649464325, 0.01585540302803141, 0.015578219804112312, 0.015347634284430778, 0.015151858307795599, 0.01498328851352858, 0.014836565434450758, 0.014707661548247772, 0.0145934335737469, 0.014491366008932659, 0.014399436807703602, 0.014316005638486673, 0.014239729034079902, 0.014169510537324093, 0.014104439906190579, 0.014043770806252675, 0.01398686905117961, 0.013933214717474805, 0.01388237143849653, 0.013833962163956694, 0.013787674431382435, 0.013743232437944673, 0.013700405061932727, 0.013658991652586886, 0.013618811572499072, 0.013579709994462398, 0.013541550827737503, 0.01350421346876582, 0.013467593625061699, 0.013431594730341917, 0.013396130246200755, 0.013361127741752748, 0.013326515075567074, 0.013292234680557966, 0.013258231798086578, 0.013224453619292946, 0.013190853816050124, 0.013157391087485603, 0.013124033604448103, 0.013090739319998686, 0.013057481175493334, 0.013024229164349576, 0.012990962963981521, 0.012957656125939849, 0.012924292622918035, 0.01289086061261433, 0.012857344425306642, 0.012823746676946152, 0.012790061725171149, 0.012756295381568947, 0.012722462096635764, 0.012688575575577054, 0.012654662432965058, 0.012620750363235636, 0.012586880944046641, 0.012553093675420573, 0.012519430943135419, 0.012485943565549518, 0.012452688697996503, 0.012419709372647036, 0.01238706134397253, 0.012354790217820752, 0.012322935540237357, 0.012291539058881475, 0.012260625771309422, 0.012230221280359613, 0.012200336277625548, 0.012170978749676637, 0.012142150194592555, 0.012113841905722447, 0.012086043859067176, 0.01205873741679874, 0.012031900941568537, 0.012005515773054098, 0.011979558637499114, 0.011954004799265587, 0.011928831757165735, 0.011904014707302497, 0.011879534443797982, 0.011855368461068936, 0.011831496689656851, 0.011807906038817153, 0.011784579377592454, 0.01176150467790775, 0.011738665495274681, 0.011716055775320842, 0.011693661917427111, 0.011671480446586438, 0.011649502293650952]
Val loss: [0.04480263218283653, 0.04083384573459625, 0.03785599768161774, 0.035197123885154724, 0.032797858119010925, 0.030637098476290703, 0.028714073821902275, 0.027047259733080864, 0.025655917823314667, 0.024532778188586235, 0.023640530183911324, 0.022932475432753563, 0.022368602454662323, 0.02191854640841484, 0.021559445187449455, 0.021273696795105934, 0.02104734256863594, 0.020869096741080284, 0.02072967030107975, 0.020621413365006447, 0.02053801529109478, 0.020474329590797424, 0.02042614109814167, 0.020390072837471962, 0.02036339044570923, 0.020343920215964317, 0.0203299131244421, 0.020319979637861252, 0.02031303010880947, 0.020308183506131172, 0.020304735749959946, 0.02030213549733162, 0.02029995061457157, 0.020297834649682045, 0.0202955175191164, 0.02029278874397278, 0.020289480686187744, 0.020285477861762047, 0.020280689001083374, 0.020275050774216652, 0.02026851288974285, 0.020261062309145927, 0.020252684131264687, 0.020243383944034576, 0.02023318223655224, 0.020222101360559464, 0.020210178568959236, 0.02019745483994484, 0.020183976739645004, 0.020169807597994804, 0.020155003294348717, 0.02013963833451271, 0.020123789086937904, 0.02010752446949482, 0.02009093575179577, 0.020074106752872467, 0.020057128742337227, 0.020040102303028107, 0.020023128017783165, 0.02000630460679531, 0.019989751279354095, 0.019973576068878174, 0.019957900047302246, 0.019942842423915863, 0.019928524270653725, 0.01991506852209568, 0.01990259252488613, 0.019891204312443733, 0.019881004467606544, 0.01987207867205143, 0.019864486530423164, 0.01985827274620533, 0.019853444769978523, 0.019849983975291252, 0.01984783075749874, 0.019846908748149872, 0.01984710618853569, 0.019848287105560303, 0.019850293174386024, 0.01985297165811062, 0.019856132566928864, 0.019859619438648224, 0.019863253459334373, 0.019866887480020523, 0.019870376214385033, 0.019873587414622307, 0.019876422360539436, 0.019878782331943512, 0.019880596548318863, 0.019881803542375565, 0.019882362335920334, 0.019882239401340485, 0.019881416112184525, 0.019879886880517006, 0.01987764984369278, 0.019874703139066696, 0.019871072843670845, 0.019866758957505226, 0.01986178383231163, 0.019856182858347893]
lr: 0.0001
batch_size: 16
num_epochs: 100
kernel_width: 4
hidden_size: 64
win_len: 24
